{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e44e73fd-52f6-4c50-93f4-9ac8a50d9959",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 104\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# Fake fileset with empty NanoEvents (we won’t actually load files)\u001b[39;00m\n\u001b[1;32m    102\u001b[0m fileset \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdummy_dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m: []}]\n\u001b[0;32m--> 104\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mrunner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfileset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfileset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocessor_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFourleptons\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtreename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvents\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43miteritems_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfilter_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_branches\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# --- Inspect results ---\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHistograms in output:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msel0\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistograms\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/coffea/processor/executor.py:1492\u001b[0m, in \u001b[0;36mRunner.__call__\u001b[0;34m(self, fileset, processor_instance, treename, uproot_options, iteritems_options)\u001b[0m\n\u001b[1;32m   1466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m   1467\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1468\u001b[0m     fileset: \u001b[38;5;28mdict\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1472\u001b[0m     iteritems_options: Optional[\u001b[38;5;28mdict\u001b[39m] \u001b[38;5;241m=\u001b[39m {},\n\u001b[1;32m   1473\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Accumulatable:\n\u001b[1;32m   1474\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run the processor_instance on a given fileset\u001b[39;00m\n\u001b[1;32m   1475\u001b[0m \n\u001b[1;32m   1476\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;124;03m            Any options to pass to ``tree.iteritems``\u001b[39;00m\n\u001b[1;32m   1491\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1492\u001b[0m     wrapped_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfileset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessor_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtreename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muproot_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteritems_options\u001b[49m\n\u001b[1;32m   1494\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_dataframes:\n\u001b[1;32m   1496\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_out  \u001b[38;5;66;03m# not wrapped anymore\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/coffea/processor/executor.py:1636\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(self, fileset, processor_instance, treename, uproot_options, iteritems_options)\u001b[0m\n\u001b[1;32m   1631\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\n\u001b[1;32m   1632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautomatic_retries, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretries, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipbadfiles, closure\n\u001b[1;32m   1633\u001b[0m )\n\u001b[1;32m   1635\u001b[0m executor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecutor\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexe_args)\n\u001b[0;32m-> 1636\u001b[0m wrapped_out, e \u001b[38;5;241m=\u001b[39m executor(chunks, closure, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wrapped_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1638\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1639\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo chunks returned results, verify ``processor`` instance structure.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m   1640\u001b[0m \u001b[38;5;124m        if you used skipbadfiles=True, it is possible all your files are bad.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1641\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "# Mini demo notebook for `get_hist` + `Fourleptons` + coffea runner\n",
    "\n",
    "# --- Setup ---\n",
    "import os\n",
    "import numpy as np\n",
    "import awkward as ak\n",
    "import hist\n",
    "\n",
    "from coffea import processor, util\n",
    "from coffea.processor import Runner\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema\n",
    "from dask.distributed import Client\n",
    "\n",
    "# --- Minimal placeholders for plotting ---\n",
    "class PlotProps:\n",
    "    def __init__(self, bins, xmin, xmax, xlabel):\n",
    "        self.bins = bins\n",
    "        self.xmin = xmin\n",
    "        self.xmax = xmax\n",
    "        self.xlabel = xlabel\n",
    "\n",
    "plot_props = {\n",
    "    \"fourmuons_mass\": PlotProps(50, 100, 150, \"m(4µ) [GeV]\"),\n",
    "    \"selectedmuons_p\": PlotProps(50, 0, 50, \"p [GeV]\"),\n",
    "}\n",
    "\n",
    "# Dummy req_hists just to satisfy get_hist\n",
    "req_hists = {\"dummy\": None}\n",
    "\n",
    "# --- get_hist function ---\n",
    "def get_hist(name, var, process, flatten=False):\n",
    "    props = plot_props[name]\n",
    "    if flatten:\n",
    "        var = ak.flatten(var, axis=None)\n",
    "    var = var[~ak.is_none(var, axis=0)]\n",
    "    if isinstance(var, ak.Array):\n",
    "        var = ak.to_numpy(var)\n",
    "\n",
    "    interactions = list(req_hists.keys())\n",
    "    myhist = (\n",
    "        hist.Hist.new\n",
    "        .Reg(props.bins, props.xmin, props.xmax, name=\"observable\", label=props.xlabel)\n",
    "        .StrCat([], name=\"dataset\", label=\"Dataset\", growth=True)\n",
    "    )\n",
    "    for pro in interactions:\n",
    "        myhist.fill(observable=var, dataset=name)\n",
    "    return myhist\n",
    "\n",
    "# --- Minimal Fourleptons processor ---\n",
    "class Fourleptons(processor.ProcessorABC):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def process(self, events):\n",
    "        # Fake data: just two variables\n",
    "        vars_sel = {\n",
    "            0: {\n",
    "                \"selectedmuons_p\": ak.Array([[5.0, 10.0, 12.0, 20.0]]),\n",
    "                \"fourmuons_mass\": ak.Array([125.0]),\n",
    "            }\n",
    "        }\n",
    "\n",
    "        Output = processor.dict_accumulator({\n",
    "            \"sel0\": processor.dict_accumulator({\n",
    "                \"histograms\": processor.dict_accumulator({\n",
    "                    name: get_hist(name, var, process=\"dummy\", flatten=True)\n",
    "                    for name, var in vars_sel[0].items()\n",
    "                }),\n",
    "                \"cutflow\": processor.dict_accumulator({\n",
    "                    \"Onecut\": 1,\n",
    "                    \"Cutflow\": [1],\n",
    "                    \"Labels\": [\"No cut\"],\n",
    "                }),\n",
    "            })\n",
    "        })\n",
    "        return Output\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator\n",
    "\n",
    "# --- Runner execution (with local dask) ---\n",
    "USE_DASK = True\n",
    "\n",
    "def filter_branches(branch_name: str) -> bool:\n",
    "    forbidden = [\"PARAMETERS\", \"_intMap\", \"_floatMap\", \"_stringMap\"]\n",
    "    return not any(substr in branch_name for substr in forbidden)\n",
    "\n",
    "if USE_DASK:\n",
    "    client = Client(\"tls://192.168.202.22:8786\")\n",
    "    executor = processor.DaskExecutor(client=client, status=True)\n",
    "else:\n",
    "    executor = processor.FuturesExecutor(workers=1)\n",
    "\n",
    "runner = Runner(\n",
    "    executor=executor,\n",
    "    schema=NanoAODSchema,\n",
    "    savemetrics=True,\n",
    "    chunksize=1000,\n",
    ")\n",
    "\n",
    "# Fake fileset with empty NanoEvents (we won’t actually load files)\n",
    "fileset = [{\"dummy_dataset\": []}]\n",
    "\n",
    "output = runner(\n",
    "    fileset=fileset[0],\n",
    "    processor_instance=Fourleptons(),\n",
    "    treename=\"Events\",\n",
    "    iteritems_options={\"filter_name\": filter_branches},\n",
    ")\n",
    "\n",
    "# --- Inspect results ---\n",
    "print(\"Histograms in output:\", output[\"sel0\"][\"histograms\"].keys())\n",
    "\n",
    "h_mass = output[\"sel0\"][\"histograms\"][\"fourmuons_mass\"]\n",
    "print(\"fourmuons_mass hist entries:\", h_mass.values())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
